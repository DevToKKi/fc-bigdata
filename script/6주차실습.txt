1. 수집 
 
Execution role : arn:aws:iam::5722222507:role/apigatewayTokinesis

#설정
{stream-name}

HTTP HEADER 
Name : Content-Type	
Mapped from : 'application/x-amz-json-1.1'


Mapping templates 

application/json

#set ( $enter = "
")
#set($json = "$input.json('$')$enter")
{
"Data": "$util.base64Encode("$json")",
"PartitionKey": "$input.params('X-Amzn-Trace-Id')",
"StreamName": "$input.params('stream-name')"
}


#Test
curl -d "{\"value\":\"30\",\"type\":\"Tip 3\"}" -H "Content-Type: application/json" -X POST https://z8lxxxxel.execute-api.ap-northeast-2.amazonaws.com/PROD/v2/class1


2. 분석

emr steps : 
s3://ap-northeast-2.elasticmapreduce/libs/script-runner/script-runner.jar
s3://fc-class/shell/mysql-driver.sh

mysql 접속정보 
myclass-instance-1.cgfpdcibdeds.ap-northeast-2.rds.amazonaws.com
id : admin 
password : Votmxm12#


------
from pyspark.sql import SparkSession

spark = SparkSession \
    .builder \
    .appName("Python Spark SQL basic example") \
    .getOrCreate()

jdbcHostname = "zbinfo-d-1.d-d.ap-northeast-1.rds.amazonaws.com"
jdbcDatabase = "spark"
username="data"
password="sparkdatapipe"
jdbcPort = 3306
jdbcUrl = "jdbc:mysql://{0}:{1}/{2}?user={3}&password={4}?characterEncoding=UTF-8".format(jdbcHostname, jdbcPort, jdbcDatabase, username, password)

sql="(select * from spark.apart_dau limit 10) a"
jdbcDF = spark.read.format("jdbc").option("driver","com.mysql.jdbc.Driver" ).option("url", jdbcUrl).option("dbtable", sql).option("user", username).option("password", password).load()

jdbcDF.show()

3. Redshift spectrum

--------------------------------------------------------
create external schema red_class from data catalog 
database 'class' 
iam_role 'arn:aws:iam::67532222402:role/redspectrum' 
region 'ap-northeast-2';
--------------------------------------------------------

select a.base_date, 
       a.danji_id, 
       b.danji_name,
       b.sido,
       b.sigungu,
       b.dong,
       count(*) as view_count
from "sample_data_dev"."red_class".danji_user_view_silver a 
join "sample_data_dev"."red_class".danji_parquet b
on a.danji_id = b.id 
group by a.base_date, 
       a.danji_id, 
       b.danji_name,
       b.sido,
       b.sigungu,
       b.dong